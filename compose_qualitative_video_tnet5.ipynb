{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_dir=\"/workspace/data/thermix_data/thermset_v1.1\"\n",
    "group=\"Fiona_001\"\n",
    "day=2\n",
    "start_hour=12\n",
    "\n",
    "modelname=\"2016-11-04_145241\"\n",
    "checkpoint=6097\n",
    "#modelname=\"2016-11-11_073507\"\n",
    "#checkpoint=2622\n",
    "modelpath=\"/workspace/data/thermix_data/tf_training/%s/checkpoint-%d\"%(modelname,checkpoint)\n",
    "tf_workspace =\"/workspace/data/thermix_data/tf_evaluation\"\n",
    "\n",
    "fps=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_filepath=os.path.join(tf_workspace,\"%s_%s_day%d.in\"%(group, modelname, day))\n",
    "output_filepath=os.path.join(tf_workspace,\"%s_%s_day%d.out\"%(group, modelname, day))\n",
    "\n",
    "video_filepath=os.path.join(tf_workspace,\"%s_%s_day%d.mov\"%(group, modelname, day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-21 15:00:00 2016-10-22 15:00:00\n",
      "frames to predict: 25926\n",
      "['/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.00.43/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.01.33/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.02.36/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.03.38/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.04.29/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.15/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.05.57/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.06.57/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/9.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/10.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.08.01/11.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/6.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/7.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.07/8.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.57/0.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.57/1.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.57/2.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.57/3.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.57/4.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.57/5.png', '/workspace/data/thermix_data/thermset_v1.1/Marge_012/2016-10-21_15.09.57/6.png']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "annotations_filename = \"%s_annotations.txt\"%group\n",
    "annotations_filepath = os.path.join(dataset_dir, group, annotations_filename)\n",
    "\n",
    "clips_path = os.path.join(dataset_dir,group)\n",
    "clips = [(c, datetime.strptime(c,\"%Y-%m-%d_%H.%M.%S\")) for c in os.listdir(clips_path) if c != annotations_filename]\n",
    "\n",
    "clips = sorted(clips, key=lambda c:c[1])\n",
    "\n",
    "start_date=(clips[0][1]+timedelta(days=day-1)).replace(hour=start_hour, minute=0, second=0)\n",
    "end_date=start_date+timedelta(days=1)\n",
    "print start_date, end_date \n",
    "\n",
    "clips_to_process=[]\n",
    "for c,d in clips:\n",
    "    if start_date <= d <= end_date:\n",
    "        clips_to_process.append(c)\n",
    "      \n",
    "input_dir = os.path.dirname(input_filepath)\n",
    "if not os.path.isdir(input_dir):\n",
    "    os.makedirs(input_dir)\n",
    "  \n",
    "frames_to_process = []\n",
    "for c in clips_to_process:\n",
    "    c_path = os.path.join(clips_path, c)\n",
    "    frames=sorted(os.listdir(c_path), key=lambda x:int(x[:-4]))\n",
    "    for fr in frames:\n",
    "        fr_path=os.path.join(c_path, fr)\n",
    "        frames_to_process.append(fr_path)\n",
    "            \n",
    "with open(input_filepath, \"w\") as f:\n",
    "    for fr_path in frames_to_process:\n",
    "        f.write(\"%s 0\\n\"%fr_path)\n",
    "\n",
    "print \"frames to predict: %d\"%len(frames_to_process)\n",
    "print frames_to_process[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNormalization/is_training:0\n"
     ]
    }
   ],
   "source": [
    "import tflearn, tensorflow as tf\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected,reshape\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import batch_normalization#local_response_normalization\n",
    "#from tflearn.layers.estimator import regression\n",
    "from training_utils import thermal_image_preloader\n",
    "\n",
    "def model(input_placeholder=None):\n",
    "    tf_data = input_placeholder or tf.placeholder(tf.float32, shape=(None, 224, 224))\n",
    "    network = input_data(placeholder=tf_data)\n",
    "    \n",
    "    network = reshape(network, [-1,224,224,1])\n",
    "    \n",
    "    network = batch_normalization(network)\n",
    "    \n",
    "    network = conv_2d(network, 96, 7, strides=2, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = batch_normalization(network)\n",
    "    \n",
    "    #network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 256, 5, strides=2, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = batch_normalization(network)\n",
    "    \n",
    "    #network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = batch_normalization(network)\n",
    "    \n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = batch_normalization(network)\n",
    "    \n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = batch_normalization(network)\n",
    "    \n",
    "    #network = local_response_normalization(network)\n",
    "    network = fully_connected(network, 5, activation='softmax')\n",
    "    \n",
    "    return network, tf_data\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Model variables\n",
    "    #The network to be used\n",
    "    with tf.device('/gpu:0'):\n",
    "        net, X_ph = model()\n",
    "\n",
    "        init = tf.initialize_all_variables()\n",
    "        vars_to_restore = []\n",
    "        for v in tf.all_variables():\n",
    "            if \"is_training\" in v.name:\n",
    "                print v.name\n",
    "                continue\n",
    "            vars_to_restore.append(v)\n",
    "        saver = tf.train.Saver(vars_to_restore)\n",
    "\n",
    "X, _ =thermal_image_preloader(input_filepath, (224,224), mode='file', normalize=False,\n",
    "                              grayscale=True, categorical_labels=True,\n",
    "                              files_extension=None, filter_channel=False)\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    tflearn.config.is_training(False,sess)\n",
    "    sess.run(init)\n",
    "    saver.restore(sess,modelpath)\n",
    "    \n",
    "    prediction = []\n",
    "    i=0\n",
    "    step = 200\n",
    "    while len(prediction) <len(X):\n",
    "        res = net.eval({X_ph:X[i:i+step]})\n",
    "        for r in res:\n",
    "            sorted_indexes = sorted(range(5), key=lambda x:r[x], reverse=True)\n",
    "            prediction.append((sorted_indexes[0], r[sorted_indexes[0]]))\n",
    "        i+=step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#save results\n",
    "with open(output_filepath, \"w\") as f:\n",
    "    for i in range(len(frames_to_process)):\n",
    "        fr_path = frames_to_process[i]\n",
    "        label = prediction[i][0]\n",
    "        score = prediction[i][1]\n",
    "        f.write(\"%s %d:%f\\n\"%(fr_path,label,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from draw_utils import draw_classification_on_image\n",
    "import shutil\n",
    "\n",
    "temp_dir= os.path.join(tf_workspace, \"temp\")\n",
    "if os.path.isdir(temp_dir):\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "os.makedirs(temp_dir)\n",
    "\n",
    "labels=[\"Sleeping\",\"Sitting\",\"Standing\",\"People\",\"Background\"]\n",
    "for i in range(len(frames_to_process)):\n",
    "    \n",
    "    fr = frames_to_process[i]\n",
    "    score = prediction[i][1]\n",
    "    label = labels[prediction[i][0]]\n",
    "    draw_classification_on_image(fr, os.path.join(temp_dir, \"%020d.png\"%i), score, label, stretch_image=True, add_date=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(video_filepath):\n",
    "    os.remove(video_filepath)\n",
    "    \n",
    "os.system(\"ffmpeg -pattern_type glob -i '%s/*.png' -r %d -c:v libx264 %s\" % (temp_dir, fps, video_filepath))\n",
    "#shutil.rmtree(temp_dir)\n",
    "os.system(\"cd youtube_upload && python upload_video.py --file=%s --title='%s Day %d' && cd ..\"% (video_filepath, group, day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def str_date(date):\n",
    "    return date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "with open(output_filepath) as f:\n",
    "    lines=f.readlines()\n",
    "\n",
    "video_lens = {}\n",
    "for line in lines:\n",
    "    fr,info = line.split()\n",
    "    \n",
    "    video_name= os.path.basename(os.path.dirname(fr))\n",
    "    if not video_lens.get(video_name):\n",
    "        video_lens[video_name]= 1\n",
    "    else:\n",
    "        video_lens[video_name]+= 1\n",
    "    \n",
    "category_lines = {}\n",
    "cat_by_index = [\"lying\", \"sitting\", \"standing\", \"people\",\"background\"]\n",
    "last_cat=None\n",
    "for line in lines:\n",
    "    fr,info = line.split()\n",
    "    cat,score=info.split(\":\")\n",
    "    str_cat=cat_by_index[int(cat)]\n",
    "    \n",
    "    video_name= os.path.basename(os.path.dirname(fr))\n",
    "    frame_index=int(os.path.basename(fr)[:-4])\n",
    "    \n",
    "    start_date= str_date(datetime.strptime(video_name,\"%Y-%m-%d_%H.%M.%S\")+timedelta(seconds=(float(frame_index)/video_lens[video_name])*5))\n",
    "    \n",
    "    if not category_lines.get(str_cat):\n",
    "        category_lines[str_cat]=[]\n",
    "    \n",
    "    if not last_cat:\n",
    "        category_lines[str_cat].append(start_date)\n",
    "        last_cat = str_cat\n",
    "        continue\n",
    "        \n",
    "    if last_cat != str_cat:\n",
    "        category_lines[last_cat].extend([start_date,None])\n",
    "        category_lines[str_cat].append(start_date)\n",
    "        last_cat = str_cat\n",
    "        \n",
    "    if line == lines[-1]:\n",
    "        category_lines[str_cat].append(start_date)\n",
    "\n",
    "for c in category_lines.keys():\n",
    "    if category_lines[c][-1] is None:\n",
    "        category_lines[c].pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/util/ssl_.py:122: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pusiol/680.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "data = []\n",
    "cat_order = [\"background\",\"lying\", \"sitting\", \"standing\", \"people\"]\n",
    "for cat in cat_order:\n",
    "    trace_p = go.Scatter(\n",
    "        x = category_lines[cat],\n",
    "        y = [cat for _ in category_lines[cat]],\n",
    "        mode = 'lines',\n",
    "        name = '%s' %(cat)\n",
    "    )\n",
    "    \n",
    "    data.append(trace_p)\n",
    "\n",
    "layout = dict(title='%s Day %d timeline'%(group, day))\n",
    "fig = dict(data=data, layout=layout)\n",
    "    \n",
    "py.iplot(fig, filename='%s Day %d timeline'%(group, day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
