{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from video_downloader import *\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email = \"fpolacov@gmail.com\"\n",
    "password = \"aaaaaa\"\n",
    "\n",
    "semantics = [\"lying\", \"sitting\", \"standing\", \"people\", \"background\"]\n",
    "bucket_groups_names = [\"bucket_\"+sem for sem in semantics]\n",
    "\n",
    "# Paths\n",
    "group_videos_path=environ.get(\"group_videos_path\",'/media/Gui2/thermix/ARThermal/olmos_001_frames_no_movement/14_tim/3')\n",
    "cnn_results=environ.get(\"cnn_results\",\"/media/Gui2/thermix/ARTraining/trained_models/thermix_33a/olmos_001_poses_classify.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from datetime import *\n",
    "from operator import attrgetter\n",
    "import requests\n",
    "\n",
    "''' returns list of video folders from group ordered by time '''\n",
    "def videos_ordered_by_time_for_group(group_path):\n",
    "    files_and_dates = []\n",
    "    \n",
    "    files = listdir(group_path)\n",
    "    for path in files:\n",
    "        files_and_dates.append(get_file_and_date(path))\n",
    "    \n",
    "    files_and_dates.sort(key=lambda item:item['date'])\n",
    "    \n",
    "    sorted_files = [os.path.join(group_path,f['path']) for f in files_and_dates]\n",
    "    return sorted_files\n",
    "\n",
    "\n",
    "def order_video_list_by_time(video_list):\n",
    "    # video_list = [video, semantic]+\n",
    "    files_and_dates = []\n",
    "    for path,semantic in video_list:\n",
    "        files_and_dates.append([get_file_and_date(path), semantic])\n",
    "    files_and_dates.sort(key=lambda item:item[0]['date'])\n",
    "#    sorted_files = [os.path.join(group_path,f['path']) for f in files_and_dates]\n",
    "    return [[f[0]['path'],f[1]] for f in files_and_dates]\n",
    "    \n",
    "''' returns time for a filename the way videos where downloaded '''\n",
    "def get_file_and_date(filename):\n",
    "    # split and remove .000*_+.mov\n",
    "    split1 = filename.split(\".\")\n",
    "    f1 = split1[0]\n",
    "    \n",
    "    # hardcode to split\n",
    "    split2 = f1.split(\"unkown_\")\n",
    "    f2 = split2[1]\n",
    "    \n",
    "    # get date\n",
    "    split3 = f2.split(\"_\")\n",
    "    date = split3[0]\n",
    "\n",
    "    # get time\n",
    "    time = split3[1]\n",
    "    split4 = time.split(\"%3A\")\n",
    "    h = split4[0]\n",
    "    m = split4[1]\n",
    "    s = split4[2]\n",
    "    \n",
    "    # since time is in backend's timezone, hardcode it to fit Argentina's timezone\n",
    "    # there's a problem when h > 01:00 h < 03:59 day will not change.\n",
    "    h_real = (int(h) - 3) % 24\n",
    "    \n",
    "    d = datetime.strptime(date+\" \"+str(h_real)+\":\"+m+\":\"+s, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return { 'path':filename, 'date':d }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join, dirname\n",
    "\n",
    "def get_semantics_for_videos(videos, cnn_results):\n",
    "\n",
    "    cnn_files = open(cnn_results,'r')\n",
    "    cnn_lines = cnn_files.readlines()\n",
    "    cnn_files.close()\n",
    "\n",
    "    return_dict = {}\n",
    "\n",
    "    for result in cnn_lines:\n",
    "        path, res, _  = result.split(' ')\n",
    "        video_path_from_path = os.path.basename(os.path.dirname(path))\n",
    "        \n",
    "        if not video_path_from_path in return_dict:\n",
    "            return_dict[video_path_from_path] = [res]\n",
    "        else:\n",
    "            return_dict[video_path_from_path].extend([res])\n",
    "\n",
    "    return return_dict\n",
    "    \n",
    "def get_frames_from_video_path(video_path):\n",
    "    files = [os.path.join(video_path,f) for f in listdir(video_path) if isfile(os.path.join(video_path, f))]\n",
    "    return sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' returns list of videos that have all same semantics ordered by time '''\n",
    "def videos_with_same_semantic_in_all_frames(videos):\n",
    "    return_list = []\n",
    "    \n",
    "    #videos = {'video_path':[semantics]}\n",
    "    for video, semantics in videos.iteritems():\n",
    "        if len(set(semantics)) == 1:\n",
    "            return_list.append([video,semantics[0]])\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "''' returns list of videos that have all semantics with semantic_id ordered by time '''\n",
    "def videos_with_semantic(videos, semantic_id):\n",
    "    return_list = []\n",
    "    \n",
    "    #videos = {'video_path':[semantics]}\n",
    "    for video, semantics in videos.iteritems():\n",
    "        if len(set(semantics)) == 1 and semantic_id in semantics:\n",
    "            return_list.append([video,semantic_id])\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "''' returns list of videos that have at least a frame with semantic_id ordered by time '''\n",
    "def videos_that_include_semantic(videos, semantic_id):\n",
    "    return_list = []\n",
    "    \n",
    "    #videos = {'video_path':[semantics]}\n",
    "    for video, semantics in videos.iteritems():\n",
    "        if semantic_id in semantics:\n",
    "            return_list.append([video,semantic_id])\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "''' returns all videos that changed their semantic from the previous one '''\n",
    "def videos_that_changed_semantic_from_previous(videos):\n",
    "    # videos = [path,semantic]+\n",
    "    return_list = [videos[0]]\n",
    "    for vid in videos[1:]:\n",
    "        last_elem = return_list[-1]\n",
    "        \n",
    "        if not last_elem[1] == vid[1]:\n",
    "            return_list.append(vid)\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "''' forwards videos to their corresponding bucket in backend '''\n",
    "def forward_videos_in_bramble(videos):\n",
    "    # user token for accessing API\n",
    "    token = login(email, password)\n",
    "    \n",
    "    # [(group_name, chat_id),...]\n",
    "    groups = get_groups_of_user_with_token(token)\n",
    "    \n",
    "    # {group_name: chat_id, } for all groups in bucket list\n",
    "    bucket_groups = dict((gname,gid) for gname,gid in groups if gname in bucket_groups_names)\n",
    "    \n",
    "    # url for forwarding video\n",
    "    forward_url = \"https://dev.thermal.us.bramblexpress.com/api/v1/entries/verzus/forward_with_name/\"\n",
    "    i = 0\n",
    "    for video,sem in videos:\n",
    "        # index of semantic in semantic list\n",
    "        sem_index = int(sem)-1\n",
    "        \n",
    "        # bucket group name for semantic index\n",
    "        gname = bucket_groups_names[sem_index]\n",
    "\n",
    "        # chat id for group\n",
    "        chat_id = bucket_groups[gname]\n",
    "        \n",
    "        # forward video to bucket group of the corresponding semantic\n",
    "        response = requests.post(forward_url,\n",
    "                                 json={'chats':[int(chat_id)],'video_name':video+\".mov\"},\n",
    "                                 verify=False,\n",
    "                                 headers={'Authorization':'Token %s' % token})\n",
    "        i +=1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: 51\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "vids = [os.path.join(group_videos_path,f) for f in listdir(group_videos_path)]\n",
    "videos_and_semantics = get_semantics_for_videos(vids, cnn_results)\n",
    "\n",
    "# get videos with same semantics\n",
    "#usable_videos = videos_with_same_semantic_in_all_frames(videos_and_semantics)\n",
    "usable_videos = videos_with_semantic(videos_and_semantics, \"2\")\n",
    "\n",
    "# order usable videos by date\n",
    "ordered_videos_by_time = order_video_list_by_time(usable_videos)\n",
    "\n",
    "# get videos with 'jumps' in semantics\n",
    "#forward_list = videos_that_changed_semantic_from_previous(ordered_videos_by_time)\n",
    "forward_list = ordered_videos_by_time\n",
    "\n",
    "ok = forward_videos_in_bramble(forward_list)\n",
    "if ok is not None:\n",
    "    print \"OK: %d\"%ok\n",
    "else:\n",
    "    print \"ERROR in forwards\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
