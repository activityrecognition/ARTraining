{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation='/media/Gui2/thermix/ARTraining/trained_models/thermix_42a/thermix_42a_testing.txt'\n",
    "'''\n",
    "if !predictions, run:\n",
    "    go\n",
    "    cd ccv/bin\n",
    "    ./cnnclassify /media/Gui2/thermix/ARTraining/trained_models/thermix_42a/thermix_42a_testing.txt \\\n",
    "                    /media/Gui2/thermix/ARTraining/trained_models/thermix_42a/thermix_42a.sqlite3 \\\n",
    "                    /media/Gui2/thermix/dataset_merged \\\n",
    "                    | tee /media/Gui2/thermix/ARTraining/trained_models/thermix_42a/thermix_42a_testing_predictions.txt\n",
    "'''\n",
    "predictions='/media/Gui2/thermix/ARTraining/trained_models/thermix_42a/thermix_42a_testing_predictions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_vs_prediction():\n",
    "    \n",
    "    val_file = open(validation, 'r')\n",
    "    val_lines = val_file.readlines()\n",
    "    val_file.close()\n",
    "\n",
    "    pred_file = open(predictions, 'r')\n",
    "    pred_lines = pred_file.readlines()\n",
    "    pred_file.close()\n",
    "        \n",
    "    vals = []\n",
    "    for line in val_lines:\n",
    "        c, p = line.rstrip().split(' ')\n",
    "        vals.append([c, p])\n",
    "        \n",
    "    preds = []\n",
    "    for line in pred_lines:\n",
    "        p, c, s = line.rstrip().split(' ')\n",
    "        preds.append([c, p, s])\n",
    "        \n",
    "    assert len(vals) == len(preds)\n",
    "    \n",
    "    all_data = []\n",
    "    for v in vals:\n",
    "        for p in preds:\n",
    "            if v[1] in p:\n",
    "                all_data.append([v[1], v[0], p[0], p[2]])\n",
    "    \n",
    "    # all_data[i] = [<path_i>, <real_class_i>, <predicted_class_i>, <prediction_score_i>]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def overall_accuracy(population):\n",
    "    tp = []\n",
    "    for y, h in population:\n",
    "        if y == h:\n",
    "            tp.append([y,h])\n",
    "    \n",
    "    accuracy = count(tp)/count(population)\n",
    "    \n",
    "    print '* class by class accuracy: %.2f %%' %(accuracy*100)\n",
    "    \n",
    "#def overall_miss_rate(population):\n",
    "#    fn = [_,0,0,0,0,0]\n",
    "#    population_classes = [_,0,0,0,0,0]\n",
    "#    for y, h in population:\n",
    "#        population_classes[y] = population_classes[y] + 1\n",
    "#        if y != h:\n",
    "#            fn[y] = fn[y] + 1\n",
    "#            \n",
    "#    miss_rate = 0            \n",
    "#    miss_rate = sum([fn[i]/population_classes[i] for i in range(1, len(population_classes))])\n",
    "#    print '* class by class miss_rate: %.2f %%' %(miss_rate*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def metrics(population):\n",
    "    print 'positive => lying, sitting, standing, people (interesting)'\n",
    "    print 'negative => background (not interesting)'\n",
    "    print '-----'\n",
    "    \n",
    "    tp = []\n",
    "    tn = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "\n",
    "    condition_positive = [[y,h] for [y,h] in data if is_positive(y)]\n",
    "    condition_negative = [[y,h] for [y,h] in data if is_negative(y)]\n",
    "    \n",
    "    assert(len(population) == len(condition_negative)+len(condition_positive))\n",
    "    \n",
    "    for y,h in population:\n",
    "        # true positive => y == 1,2,3,4 and h == 1,2,3,4\n",
    "        if is_positive(y) and is_positive(h):\n",
    "            tp.append([y,h])\n",
    "            \n",
    "        # get true negatives\n",
    "        elif is_negative(y) and is_negative(h):\n",
    "            tn.append([y,h])\n",
    "            \n",
    "        # get false positives => y == 5 and h == 1,2,3,4\n",
    "        elif is_negative(y) and is_positive(h):\n",
    "            fp.append([y,h])\n",
    "            \n",
    "        # get false negatives\n",
    "        elif is_positive(y) and is_negative(h):\n",
    "            fn.append([y,h])\n",
    "            \n",
    "    assert(len(tp)+len(tn)+len(fp)+len(fn) == len(population))\n",
    "    \n",
    "    # sensitivity = true positives / real positives\n",
    "    sensitivity = count(tp)/count(condition_positive)\n",
    "    \n",
    "    # specificity = true negatives / real negatives\n",
    "    specificity = count(tn)/count(condition_negative)\n",
    "    \n",
    "    # precision = true positives / total of correct predictions\n",
    "    precision = count(tp)/(count(tp)+count(fp))\n",
    "    \n",
    "    # negative predictive value = true negatives / total of correct predictions\n",
    "    negative_predictive_value = count(tn)/(count(tn)+count(fn))\n",
    "    \n",
    "    # accuracy = correct predicitons / size of population\n",
    "    accuracy = (count(tp)+count(tn))/(count(population))\n",
    "    \n",
    "    print '* accuracy: %.2f %%' %(accuracy*100)\n",
    "    print '* sensitivity (recall, true positive rate): %.2f %%' %(sensitivity*100)\n",
    "    print '* specificity (true negative rate): %.2f %%' %(specificity*100)\n",
    "    print '* precision (positive predictive value) : %.2f %%' %(precision*100)\n",
    "    print '* negative predictive value: %.2f %%' %(negative_predictive_value*100)\n",
    "    print '* fall-out (false positive rate): %.2f %%' %((1-specificity)*100)\n",
    "    print '* miss-rate (false negative rate): %.2f %%' %((1-sensitivity)*100)\n",
    "    print '* false-discovery-rate: %.2f %%' %((1-precision)*100)\n",
    "    \n",
    "    \n",
    "def is_positive(x):\n",
    "    return (x == 1 or x == 2 or x == 3 or x == 4)\n",
    "\n",
    "def is_negative(x):\n",
    "    return (x == 5)\n",
    "\n",
    "def count(arr):\n",
    "    return float(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ['lying', 'sitting', 'standing', 'people', 'background']\n",
    "def get_confusion_matrix(data):\n",
    "    # all_data[i] = [<path_i>, <real_class_i>, <predicted_class_i>, <prediction_score_i>]\n",
    "    y_true = [y for y,_ in data]\n",
    "    y_pred = [y for _,y in data]\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "#    plt.figure()\n",
    "#    plot_confusion_matrix(cm)\n",
    "#    print(cm)\n",
    "#    plt.show()\n",
    "    \n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples\n",
    "    # in each class)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm_normalized)\n",
    "    \n",
    "    #plt.figure()\n",
    "    #plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "    #plt.show()\n",
    "\n",
    "    plotly_confusion_matrix(cm_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''plots in jupyter the confusion matrix'''\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('y')\n",
    "    plt.xlabel('h(x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/util/ssl_.py:318: SNIMissingWarning: An HTTPS request has been made, but the SNI (Subject Name Indication) extension to TLS is not available on this platform. This may cause the server to present an incorrect TLS certificate, which can cause validation failures. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#snimissingwarning.\n",
      "  SNIMissingWarning\n",
      "/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/util/ssl_.py:122: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "  InsecurePlatformWarning\n"
     ]
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "def plotly_confusion_matrix(cm, title='Confusion matrix '+os.path.basename(validation)):\n",
    "    annotations = []\n",
    "    for n, row in enumerate(cm):\n",
    "        for m, val in enumerate(row):\n",
    "            var = cm[n][m]\n",
    "            annotations.append(\n",
    "                dict(\n",
    "                    text=str(truncate(val,3)),\n",
    "                    x=classes[m], y=classes[n],\n",
    "                    xref='x1', yref='y1',\n",
    "                    font=dict(color='white'),\n",
    "                    showarrow=False)\n",
    "                )\n",
    "    data = [\n",
    "        go.Heatmap(\n",
    "            x=classes,\n",
    "            y=classes,\n",
    "            z=cm,\n",
    "#            colorscale='Viridis'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "            title='Confusion Matrix',\n",
    "            annotations=annotations,\n",
    "            xaxis=dict(title='Predicted value',),\n",
    "            yaxis=dict(title='Real value',)\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    py.iplot(fig, filename=os.path.basename(validation)+' confusion matrix')\n",
    "    \n",
    "def truncate(f, n):\n",
    "    '''Truncates/pads a float f to n decimal places without rounding'''\n",
    "    s = '{}'.format(f)\n",
    "    if 'e' in s or 'E' in s:\n",
    "        return '{0:.{1}f}'.format(f, n)\n",
    "    i, p, d = s.partition('.')\n",
    "    return '.'.join([i, (d+'0'*n)[:n]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation: thermix_42a_testing.txt\n",
      "prediction: thermix_42a_testing_predictions.txt\n",
      "-----\n",
      "positive => lying, sitting, standing, people (interesting)\n",
      "negative => background (not interesting)\n",
      "-----\n",
      "* accuracy: 98.20 %\n",
      "* sensitivity (recall, true positive rate): 98.97 %\n",
      "* specificity (true negative rate): 95.05 %\n",
      "* precision (positive predictive value) : 98.78 %\n",
      "* negative predictive value: 95.81 %\n",
      "* fall-out (false positive rate): 4.95 %\n",
      "* miss-rate (false negative rate): 1.03 %\n",
      "* false-discovery-rate: 1.22 %\n",
      "* class by class accuracy: 91.91 %\n",
      "[[  9.68e-01   3.96e-03   0.00e+00   0.00e+00   2.77e-02]\n",
      " [  8.38e-02   8.85e-01   8.88e-03   2.27e-02   0.00e+00]\n",
      " [  1.48e-02   1.09e-02   9.42e-01   1.98e-02   1.29e-02]\n",
      " [  7.55e-02   3.21e-02   3.78e-02   8.54e-01   9.44e-04]\n",
      " [  4.75e-02   0.00e+00   1.98e-03   0.00e+00   9.51e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/requests/packages/urllib3/util/ssl_.py:122: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'validation: '+os.path.basename(validation)\n",
    "print 'prediction: '+os.path.basename(predictions)\n",
    "print '-----'\n",
    "data = [[int(y),int(h)] for _,y,h,_ in get_validation_vs_prediction()]\n",
    "metrics(data)\n",
    "overall_accuracy(data)\n",
    "get_confusion_matrix(data)\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#print accuracy_score([y for _,y,_,_ in get_validation_vs_prediction()], [y for _,_,y,_ in get_validation_vs_prediction()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
