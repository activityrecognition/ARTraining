{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from matplotlib.pyplot import *\n",
    "import os\n",
    "import requests\n",
    "\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "plotly.tools.set_credentials_file(username='pusiol', api_key='m6iurl7f89')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'output_thermix_12.file'\n",
    "base_dir = '/media/Gui2/thermix/ARTraining/trained_models/thermix_12_04-06-2016'\n",
    "\n",
    "training_batch_count = 85\n",
    "testing_batch_count = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 6.25% at 2 / 85 (0.716 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 9.77% at 3 / 85 (0.616 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 8.59% at 4 / 85 (0.610 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 8.98% at 5 / 85 (0.607 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 9.69% at 6 / 85 (0.608 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 10.81% at 7 / 85 (0.608 sec)\n",
      "- at epoch 144 / 1000 => stochastic gradient descent with miss rate 10.71% at 8 / 85 (0.611 sec)\n",
      "- at epoch 144 / 1000 => stochastic gradient descent with miss rate 10.55% at 9 / 85 (0.608 sec)\n",
      "- at epoch 144 / 1000 => stochastic gradient descent with miss rate 10.94% at 10 / 85 (0.626 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.09% at 11 / 85 (0.608 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.15% at 12 / 85 (0.614 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.20% at 13 / 85 (0.609 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.42% at 14 / 85 (0.612 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.72% at 15 / 85 (0.613 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.88% at 16 / 85 (0.611 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.40% at 17 / 85 (0.620 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.13% at 18 / 85 (0.610 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.07% at 19 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.13% at 20 / 85 (0.611 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.95% at 21 / 85 (0.614 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.09% at 22 / 85 (0.609 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.07% at 23 / 85 (0.614 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.13% at 24 / 85 (0.608 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.24% at 25 / 85 (0.611 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.12% at 26 / 85 (0.617 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.08% at 27 / 85 (0.615 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.01% at 28 / 85 (0.614 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.83% at 29 / 85 (0.616 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.77% at 30 / 85 (0.612 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.90% at 31 / 85 (0.616 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.90% at 32 / 85 (0.615 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.94% at 33 / 85 (0.616 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.00% at 34 / 85 (0.614 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.88% at 35 / 85 (0.615 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.90% at 36 / 85 (0.617 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.85% at 37 / 85 (0.615 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.82% at 38 / 85 (0.615 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.90% at 39 / 85 (0.615 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.90% at 40 / 85 (0.616 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.97% at 41 / 85 (0.616 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.02% at 42 / 85 (0.616 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.03% at 43 / 85 (0.620 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.03% at 44 / 85 (0.616 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.07% at 45 / 85 (0.614 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.08% at 46 / 85 (0.618 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.16% at 47 / 85 (0.619 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.13% at 48 / 85 (0.619 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.06% at 49 / 85 (0.619 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.09% at 50 / 85 (0.623 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.08% at 51 / 85 (0.618 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.01% at 52 / 85 (0.614 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 12.03% at 53 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.95% at 54 / 85 (0.624 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.91% at 55 / 85 (0.618 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.89% at 56 / 85 (0.617 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.86% at 57 / 85 (0.619 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.95% at 58 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.95% at 59 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.92% at 60 / 85 (0.623 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.85% at 61 / 85 (0.620 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.86% at 62 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.81% at 63 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.83% at 64 / 85 (0.624 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.87% at 65 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.91% at 66 / 85 (0.619 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.86% at 67 / 85 (0.618 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.84% at 68 / 85 (0.622 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.90% at 69 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.93% at 70 / 85 (0.621 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.89% at 71 / 85 (0.618 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.91% at 72 / 85 (0.620 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.88% at 73 / 85 (0.624 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.84% at 74 / 85 (0.623 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.92% at 75 / 85 (0.619 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.89% at 76 / 85 (0.624 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.85% at 77 / 85 (0.622 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.83% at 78 / 85 (0.622 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.87% at 79 / 85 (0.623 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.82% at 80 / 85 (0.622 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.87% at 81 / 85 (0.623 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.82% at 82 / 85 (0.629 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.82% at 83 / 85 (0.623 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.89% at 84 / 85 (0.622 sec)\n",
      " - at epoch 144 / 1000 => stochastic gradient descent with miss rate 11.90% at 85 / 85 (0.624 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 27.34% at 2 / 24 (0.493 sec)\n",
      "- at epoch 144 / 1000 => with miss rate 23.44% at 3 / 24 (0.502 sec)\n",
      "- at epoch 144 / 1000 => with miss rate 21.35% at 4 / 24 (0.504 sec)\n",
      "- at epoch 144 / 1000 => with miss rate 21.88% at 5 / 24 (0.532 sec)\n",
      "- at epoch 144 / 1000 => with miss rate 20.78% at 6 / 24 (0.525 sec)\n",
      "- at epoch 144 / 1000 => with miss rate 20.44% at 7 / 24 (0.512 sec)\n",
      "- at epoch 144 / 1000 => with miss rate 19.87% at 8 / 24 (0.527 sec)\n",
      "- at epoch 144 / 1000 => with miss rate 20.31% at 9 / 24 (0.499 sec)\n",
      "- at epoch 144 / 1000 => with miss rate 19.62% at 10 / 24 (0.529 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.08% at 11 / 24 (0.504 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.31% at 12 / 24 (0.540 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 19.99% at 13 / 24 (0.520 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.25% at 14 / 24 (0.540 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.09% at 15 / 24 (0.529 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.52% at 16 / 24 (0.508 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.56% at 17 / 24 (0.471 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.40% at 18 / 24 (0.538 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.62% at 19 / 24 (0.513 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.81% at 20 / 24 (0.524 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 20.86% at 21 / 24 (0.526 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 21.06% at 22 / 24 (0.494 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 21.20% at 23 / 24 (0.527 sec)\n",
      " - at epoch 144 / 1000 => with miss rate 21.16% at 24 / 24 (0.222 sec)\n",
      " - at epoch 144 / 1000 (001 - 85) => with miss rate 21.08% (65.521 sec)\n",
      "\n",
      " - at epoch 145 / 1000 => stochastic gradient descent with miss rate 10.16% at 2 / 85 (0.626 sec)\n",
      "- at epoch 145 / 1000 => stochastic gradient descent with miss rate 9.38% at 3 / 85 (0.626 sec)\n",
      " - at epoch 145 / 1000 => stochastic gradient descent with miss rate 10.68% at 4 / 85 (0.623 sec)\n",
      "- at epoch 145 / 1000 => stochastic gradient descent with miss rate 11.13% at 5 / 85 (0.620 sec)\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(base_dir,filename),'r') as f:\n",
    "    # get all lines in file\n",
    "    lines = f.readlines()\n",
    "\n",
    "    # remove all those weird chars\n",
    "    newlines = []\n",
    "    for line in lines:\n",
    "        newline = line.replace('\\x08',' ')\n",
    "        newlines.append(filter(None, newline.split('  ')))\n",
    "\n",
    "    #now search for 75 / 75 (training) y 16 / 16 (validation)\n",
    "    training_error_text = '%d / %d' % (training_batch_count,training_batch_count)\n",
    "    validation_error_text = '%d / %d' % (testing_batch_count, testing_batch_count)\n",
    "\n",
    "    training_error_lines = []\n",
    "    validation_error_lines = []\n",
    "    for a in newlines:\n",
    "        for s in a:\n",
    "            print s\n",
    "            if training_error_text in s:\n",
    "                training_error_lines.append(s)\n",
    "            if validation_error_text in s:\n",
    "                validation_error_lines.append(s)\n",
    "\n",
    "    # get matrix for validation loss\n",
    "    v_loss = []\n",
    "    for v_data in validation_error_lines:\n",
    "        index_rate = v_data.index('rate')\n",
    "        v_loss.append(float(v_data[index_rate+4:index_rate+10].replace('%','').replace(' ','')))\n",
    "\n",
    "    # get matrix for training loss\n",
    "    t_loss = []\n",
    "    for t_data in training_error_lines:\n",
    "        index_rate = t_data.index('rate')\n",
    "        t_loss.append(float(t_data[index_rate+4:index_rate+10].replace('%','').replace(' ','')))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print v_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pusiol/119.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot data\n",
    "data = []\n",
    "Ys = [('validation sparse softmax cross entropy loss', v_loss), ('training sparse softmax cross entropy loss', t_loss)]\n",
    "for title, _Y in Ys:\n",
    "    # t = 1 -> validation data\n",
    "    _X = range(1,len(_Y)+1) # _X = epoch number\n",
    "    mom = Scatter(x=_X,y=_Y, mode ='lines+markers', name =title ,line = dict(width = 4))\n",
    "    data.append(mom)\n",
    "\n",
    "layout = Layout(title='%s loss function'%filename.split(\".\")[0], xaxis = dict(title = 'Epoch'), yaxis = dict(title = 'miss rate'), )\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "#upload to guido's account\n",
    "py.iplot(fig, filename=filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
